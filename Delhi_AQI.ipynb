{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e24f41a4-371a-4214-bf6d-f5b7fdcdbdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d48f3d44-af48-4c64-b001-d626a70dea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"DelhiAQI.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3ab463a-05e2-4bc2-825b-59d781416dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOx</th>\n",
       "      <th>NH3</th>\n",
       "      <th>CO</th>\n",
       "      <th>SO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>Benzene</th>\n",
       "      <th>Toluene</th>\n",
       "      <th>Xylene</th>\n",
       "      <th>AQI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>454.58</td>\n",
       "      <td>935.18</td>\n",
       "      <td>81.52</td>\n",
       "      <td>41.78</td>\n",
       "      <td>187.66</td>\n",
       "      <td>27.54</td>\n",
       "      <td>9.29</td>\n",
       "      <td>3.41</td>\n",
       "      <td>54.94</td>\n",
       "      <td>25.24</td>\n",
       "      <td>58.57</td>\n",
       "      <td>13.80</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>440.44</td>\n",
       "      <td>935.18</td>\n",
       "      <td>70.80</td>\n",
       "      <td>43.46</td>\n",
       "      <td>176.83</td>\n",
       "      <td>27.72</td>\n",
       "      <td>13.28</td>\n",
       "      <td>3.88</td>\n",
       "      <td>50.53</td>\n",
       "      <td>23.10</td>\n",
       "      <td>49.37</td>\n",
       "      <td>15.63</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>409.09</td>\n",
       "      <td>935.18</td>\n",
       "      <td>132.46</td>\n",
       "      <td>41.19</td>\n",
       "      <td>141.02</td>\n",
       "      <td>28.94</td>\n",
       "      <td>29.67</td>\n",
       "      <td>2.83</td>\n",
       "      <td>19.33</td>\n",
       "      <td>19.04</td>\n",
       "      <td>38.94</td>\n",
       "      <td>17.18</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>436.12</td>\n",
       "      <td>935.18</td>\n",
       "      <td>84.78</td>\n",
       "      <td>39.55</td>\n",
       "      <td>102.84</td>\n",
       "      <td>29.30</td>\n",
       "      <td>21.76</td>\n",
       "      <td>4.33</td>\n",
       "      <td>20.08</td>\n",
       "      <td>13.99</td>\n",
       "      <td>27.53</td>\n",
       "      <td>16.82</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>415.88</td>\n",
       "      <td>976.99</td>\n",
       "      <td>60.24</td>\n",
       "      <td>37.41</td>\n",
       "      <td>80.12</td>\n",
       "      <td>30.84</td>\n",
       "      <td>26.19</td>\n",
       "      <td>6.17</td>\n",
       "      <td>16.00</td>\n",
       "      <td>11.14</td>\n",
       "      <td>21.99</td>\n",
       "      <td>14.29</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>57.89</td>\n",
       "      <td>193.89</td>\n",
       "      <td>24.06</td>\n",
       "      <td>76.82</td>\n",
       "      <td>97.99</td>\n",
       "      <td>34.48</td>\n",
       "      <td>1.13</td>\n",
       "      <td>12.87</td>\n",
       "      <td>59.50</td>\n",
       "      <td>3.02</td>\n",
       "      <td>10.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>56.32</td>\n",
       "      <td>200.33</td>\n",
       "      <td>21.57</td>\n",
       "      <td>68.99</td>\n",
       "      <td>87.61</td>\n",
       "      <td>28.56</td>\n",
       "      <td>1.20</td>\n",
       "      <td>11.10</td>\n",
       "      <td>67.80</td>\n",
       "      <td>3.51</td>\n",
       "      <td>12.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>50.93</td>\n",
       "      <td>177.50</td>\n",
       "      <td>18.47</td>\n",
       "      <td>65.41</td>\n",
       "      <td>80.13</td>\n",
       "      <td>23.19</td>\n",
       "      <td>1.16</td>\n",
       "      <td>10.55</td>\n",
       "      <td>57.38</td>\n",
       "      <td>3.39</td>\n",
       "      <td>10.11</td>\n",
       "      <td>0.02</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>69.22</td>\n",
       "      <td>182.72</td>\n",
       "      <td>19.67</td>\n",
       "      <td>56.50</td>\n",
       "      <td>73.91</td>\n",
       "      <td>22.19</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.67</td>\n",
       "      <td>70.40</td>\n",
       "      <td>2.48</td>\n",
       "      <td>7.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>70.56</td>\n",
       "      <td>191.22</td>\n",
       "      <td>17.76</td>\n",
       "      <td>52.92</td>\n",
       "      <td>68.44</td>\n",
       "      <td>22.22</td>\n",
       "      <td>0.99</td>\n",
       "      <td>10.12</td>\n",
       "      <td>73.36</td>\n",
       "      <td>2.37</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PM2.5    PM10      NO    NO2     NOx    NH3     CO    SO2     O3  \\\n",
       "0      454.58  935.18   81.52  41.78  187.66  27.54   9.29   3.41  54.94   \n",
       "1      440.44  935.18   70.80  43.46  176.83  27.72  13.28   3.88  50.53   \n",
       "2      409.09  935.18  132.46  41.19  141.02  28.94  29.67   2.83  19.33   \n",
       "3      436.12  935.18   84.78  39.55  102.84  29.30  21.76   4.33  20.08   \n",
       "4      415.88  976.99   60.24  37.41   80.12  30.84  26.19   6.17  16.00   \n",
       "...       ...     ...     ...    ...     ...    ...    ...    ...    ...   \n",
       "14995   57.89  193.89   24.06  76.82   97.99  34.48   1.13  12.87  59.50   \n",
       "14996   56.32  200.33   21.57  68.99   87.61  28.56   1.20  11.10  67.80   \n",
       "14997   50.93  177.50   18.47  65.41   80.13  23.19   1.16  10.55  57.38   \n",
       "14998   69.22  182.72   19.67  56.50   73.91  22.19   1.00   9.67  70.40   \n",
       "14999   70.56  191.22   17.76  52.92   68.44  22.22   0.99  10.12  73.36   \n",
       "\n",
       "       Benzene  Toluene  Xylene  AQI  \n",
       "0        25.24    58.57   13.80  653  \n",
       "1        23.10    49.37   15.63  645  \n",
       "2        19.04    38.94   17.18  532  \n",
       "3        13.99    27.53   16.82  561  \n",
       "4        11.14    21.99   14.29  567  \n",
       "...        ...      ...     ...  ...  \n",
       "14995     3.02    10.32    0.00  192  \n",
       "14996     3.51    12.59    0.00  192  \n",
       "14997     3.39    10.11    0.02  191  \n",
       "14998     2.48     7.02    0.00  189  \n",
       "14999     2.37     7.70    0.00  189  \n",
       "\n",
       "[15000 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "12946ab2-6e7c-456f-b233-ee19c57ed9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(columns=['AQI'], inplace=False)\n",
    "y=df['AQI']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c5717d7f-796d-463c-b725-85effed26289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_eval, y_val, y_eval=train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_np = X_train.values\n",
    "X_train_scaled = scaler.fit_transform(X_train_np)\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    " \n",
    "X_val_np = X_val.values\n",
    "X_val_scaled = scaler.transform(X_val_np)\n",
    "X_val_scaled_df = pd.DataFrame(X_val_scaled, columns=X_val.columns)\n",
    " \n",
    "X_eval_np = X_eval.values\n",
    "X_eval_scaled = scaler.transform(X_eval_np)\n",
    "X_eval_scaled_df = pd.DataFrame(X_eval_scaled, columns=X_eval.columns)\n",
    " \n",
    "scalerY = MinMaxScaler()\n",
    "y_train_scaled = scalerY.fit_transform(y_train.values.reshape(-1,1))\n",
    "y_val_scaled = scalerY.transform(y_val.values.reshape(-1,1))\n",
    "y_eval_scaled = scalerY.transform(y_eval.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cc1d8275-f39a-46ae-9ffb-be7db2900e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.initializers import GlorotUniform, HeUniform\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.callbacks import Callback\n",
    " \n",
    "class Model1:\n",
    "    def __init__(Self, X_train, y_train, X_val, y_val, X_eval, y_eval):\n",
    "        Self.X_train = X_train\n",
    "        Self.X_val = X_val\n",
    "        Self.X_eval = X_eval\n",
    "        Self.y_train = y_train\n",
    "        Self.y_val = y_val\n",
    "        Self.y_eval = y_eval\n",
    "    def train(self):\n",
    "        class AccuracyCallback(Callback):\n",
    "            def on_epoch_end(self, epoch, logs={}):\n",
    "                print(f\"Epoch {epoch + 1}, Training Accuracy: {logs['accuracy']:.4f}, Validation Accuracy: {logs['val_accuracy']:.4f}\")\n",
    "        accuracy_callback = AccuracyCallback()\n",
    "        self.model = tf.keras.Sequential()\n",
    "        self.model.add(tf.keras.layers.Dense(32, activation='sigmoid', kernel_initializer=GlorotUniform()))\n",
    "        self.model.add(tf.keras.layers.Dense(16, activation='relu', kernel_initializer=HeUniform()))\n",
    "        self.model.add(tf.keras.layers.Dense(1, activation='relu', kernel_initializer=HeUniform()))\n",
    "        self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss='mse', metrics=['mae'])\n",
    "        self.model.fit(self.X_train, self.y_train, batch_size=16, epochs=20, validation_data=(self.X_val, self.y_val))\n",
    " \n",
    "    def predict_check_mean_square_error(self, scalerY):\n",
    "        predictions = self.model.predict(self.X_eval)\n",
    "        inverse_transform = scalerY.inverse_transform(self.y_eval)\n",
    "        predictions = self.model.predict(self.X_eval)\n",
    "        inverse_pred = scalerY.inverse_transform(predictions)\n",
    "        rmse = mean_squared_error(inverse_pred, inverse_transform, squared=False)\n",
    "        print(f\"RMSE = {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d4fcc432-c7be-42e7-809a-1a99c5a90f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.1558 - mae: 0.3569 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 2/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1551 - mae: 0.3552 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 3/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1582 - mae: 0.3592 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 4/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1572 - mae: 0.3575 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 5/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1566 - mae: 0.3574 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1555 - mae: 0.3570 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 7/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1540 - mae: 0.3550 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 8/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1543 - mae: 0.3558 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 9/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1562 - mae: 0.3571 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 10/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1537 - mae: 0.3544 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 11/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1570 - mae: 0.3571 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 12/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1554 - mae: 0.3563 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 13/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1570 - mae: 0.3582 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 14/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1583 - mae: 0.3588 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 15/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1558 - mae: 0.3566 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 16/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1559 - mae: 0.3572 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 17/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1560 - mae: 0.3578 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 18/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1565 - mae: 0.3574 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 19/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1530 - mae: 0.3532 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 20/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1565 - mae: 0.3571 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "RMSE = 224.43314520512934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rksah\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "m1 = Model1(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, X_eval_scaled, y_eval_scaled)\n",
    "m1.train()\n",
    "m1.predict_check_mean_square_error(scalerY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "05848b20-fb5e-4559-a365-6bf87c6386c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.0178 - mae: 0.1058 - val_loss: 0.0110 - val_mae: 0.0836\n",
      "Epoch 2/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0128 - mae: 0.0899 - val_loss: 0.0106 - val_mae: 0.0819\n",
      "Epoch 3/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0107 - mae: 0.0809 - val_loss: 0.0101 - val_mae: 0.0790\n",
      "Epoch 4/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0111 - mae: 0.0827 - val_loss: 0.0102 - val_mae: 0.0794\n",
      "Epoch 5/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0109 - mae: 0.0822 - val_loss: 0.0108 - val_mae: 0.0800\n",
      "Epoch 6/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0110 - mae: 0.0820 - val_loss: 0.0101 - val_mae: 0.0792\n",
      "Epoch 7/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0102 - mae: 0.0793 - val_loss: 0.0098 - val_mae: 0.0766\n",
      "Epoch 8/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0103 - mae: 0.0795 - val_loss: 0.0096 - val_mae: 0.0758\n",
      "Epoch 9/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0104 - mae: 0.0794 - val_loss: 0.0107 - val_mae: 0.0820\n",
      "Epoch 10/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0103 - mae: 0.0792 - val_loss: 0.0097 - val_mae: 0.0769\n",
      "Epoch 11/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0102 - mae: 0.0789 - val_loss: 0.0096 - val_mae: 0.0764\n",
      "Epoch 12/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0104 - mae: 0.0795 - val_loss: 0.0103 - val_mae: 0.0808\n",
      "Epoch 13/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0103 - mae: 0.0796 - val_loss: 0.0098 - val_mae: 0.0777\n",
      "Epoch 14/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0100 - mae: 0.0779 - val_loss: 0.0099 - val_mae: 0.0777\n",
      "Epoch 15/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0098 - mae: 0.0773 - val_loss: 0.0092 - val_mae: 0.0743\n",
      "Epoch 16/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0101 - mae: 0.0786 - val_loss: 0.0104 - val_mae: 0.0808\n",
      "Epoch 17/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0100 - mae: 0.0782 - val_loss: 0.0094 - val_mae: 0.0749\n",
      "Epoch 18/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0098 - mae: 0.0774 - val_loss: 0.0093 - val_mae: 0.0755\n",
      "Epoch 19/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0099 - mae: 0.0781 - val_loss: 0.0095 - val_mae: 0.0759\n",
      "Epoch 20/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0096 - mae: 0.0767 - val_loss: 0.0091 - val_mae: 0.0745\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step\n",
      "RMSE = 56.445960850972824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rksah\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.initializers import GlorotUniform, HeUniform\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.callbacks import Callback\n",
    " \n",
    "class Model2:\n",
    "    def __init__(Self, X_train, y_train, X_val, y_val, X_eval, y_eval):\n",
    "        Self.X_train = X_train\n",
    "        Self.X_val = X_val\n",
    "        Self.X_eval = X_eval\n",
    "        Self.y_train = y_train\n",
    "        Self.y_val = y_val\n",
    "        Self.y_eval = y_eval\n",
    "    def train(self):\n",
    "        class AccuracyCallback(Callback):\n",
    "            def on_epoch_end(self, epoch, logs={}):\n",
    "                print(f\"Epoch {epoch + 1}, Training Accuracy: {logs['accuracy']:.4f}, Validation Accuracy: {logs['val_accuracy']:.4f}\")\n",
    "        accuracy_callback = AccuracyCallback()\n",
    "        self.model = tf.keras.Sequential()\n",
    "        self.model.add(tf.keras.layers.Dense(32, activation='sigmoid', kernel_initializer=GlorotUniform()))\n",
    "        self.model.add(tf.keras.layers.Dense(8, activation='sigmoid', kernel_initializer=HeUniform()))\n",
    "        self.model.add(tf.keras.layers.Dense(1, activation='relu', kernel_initializer=HeUniform()))\n",
    "        self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss='mse', metrics=['mae'])\n",
    "        self.model.fit(self.X_train, self.y_train, batch_size=8, epochs=20, validation_data=(self.X_val, self.y_val))\n",
    " \n",
    "    def predict_check_mean_square_error(self, scalerY):\n",
    "        predictions = self.model.predict(self.X_eval)\n",
    "        inverse_transform = scalerY.inverse_transform(self.y_eval)\n",
    "        predictions = self.model.predict(self.X_eval)\n",
    "        inverse_pred = scalerY.inverse_transform(predictions)\n",
    "        rmse = mean_squared_error(inverse_pred, inverse_transform, squared=False)\n",
    "        print(f\"RMSE = {rmse}\")\n",
    "\n",
    "\n",
    "\n",
    "m2 = Model2(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, X_eval_scaled, y_eval_scaled)\n",
    "m2.train()\n",
    "m2.predict_check_mean_square_error(scalerY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "453e332f-a8e3-4702-9fc6-0e8c48b7ba20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1541 - mae: 0.3551 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 2/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1571 - mae: 0.3578 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 3/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1553 - mae: 0.3558 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 4/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1554 - mae: 0.3562 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 5/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1556 - mae: 0.3557 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1560 - mae: 0.3568 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 7/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1548 - mae: 0.3554 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 8/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1567 - mae: 0.3577 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 9/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1565 - mae: 0.3571 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 10/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1558 - mae: 0.3571 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 11/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1526 - mae: 0.3533 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 12/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1585 - mae: 0.3611 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 13/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1571 - mae: 0.3588 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 14/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1556 - mae: 0.3561 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 15/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1562 - mae: 0.3573 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 16/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1558 - mae: 0.3569 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 17/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1545 - mae: 0.3551 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 18/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1572 - mae: 0.3589 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 19/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1563 - mae: 0.3570 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 20/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1560 - mae: 0.3568 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 1/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0159 - mae: 0.0997 - val_loss: 0.0109 - val_mae: 0.0832\n",
      "Epoch 2/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0118 - mae: 0.0855 - val_loss: 0.0105 - val_mae: 0.0809\n",
      "Epoch 3/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0116 - mae: 0.0852 - val_loss: 0.0102 - val_mae: 0.0791\n",
      "Epoch 4/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0109 - mae: 0.0823 - val_loss: 0.0104 - val_mae: 0.0804\n",
      "Epoch 5/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0108 - mae: 0.0812 - val_loss: 0.0108 - val_mae: 0.0809\n",
      "Epoch 6/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0111 - mae: 0.0824 - val_loss: 0.0097 - val_mae: 0.0766\n",
      "Epoch 7/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0105 - mae: 0.0804 - val_loss: 0.0101 - val_mae: 0.0783\n",
      "Epoch 8/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0105 - mae: 0.0797 - val_loss: 0.0100 - val_mae: 0.0775\n",
      "Epoch 9/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0105 - mae: 0.0799 - val_loss: 0.0101 - val_mae: 0.0791\n",
      "Epoch 10/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0104 - mae: 0.0795 - val_loss: 0.0121 - val_mae: 0.0886\n",
      "Epoch 11/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0106 - mae: 0.0807 - val_loss: 0.0098 - val_mae: 0.0776\n",
      "Epoch 12/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0104 - mae: 0.0796 - val_loss: 0.0094 - val_mae: 0.0751\n",
      "Epoch 13/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0101 - mae: 0.0787 - val_loss: 0.0096 - val_mae: 0.0766\n",
      "Epoch 14/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0099 - mae: 0.0778 - val_loss: 0.0095 - val_mae: 0.0752\n",
      "Epoch 15/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0100 - mae: 0.0783 - val_loss: 0.0099 - val_mae: 0.0770\n",
      "Epoch 16/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0104 - mae: 0.0799 - val_loss: 0.0098 - val_mae: 0.0772\n",
      "Epoch 17/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0104 - mae: 0.0795 - val_loss: 0.0094 - val_mae: 0.0751\n",
      "Epoch 18/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0098 - mae: 0.0770 - val_loss: 0.0092 - val_mae: 0.0740\n",
      "Epoch 19/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0102 - mae: 0.0791 - val_loss: 0.0105 - val_mae: 0.0793\n",
      "Epoch 20/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0098 - mae: 0.0774 - val_loss: 0.0091 - val_mae: 0.0734\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The layer sequential_51 has never been called and thus has no defined input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 91\u001b[0m\n\u001b[0;32m     89\u001b[0m model3 \u001b[38;5;241m=\u001b[39m Model3(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, X_eval_scaled, y_eval_scaled, scalerY)\n\u001b[0;32m     90\u001b[0m model3\u001b[38;5;241m.\u001b[39mtrain_models()\n\u001b[1;32m---> 91\u001b[0m X_train_features, X_val_features, X_eval_features \u001b[38;5;241m=\u001b[39m \u001b[43mmodel3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m svr_model \u001b[38;5;241m=\u001b[39m model3\u001b[38;5;241m.\u001b[39mtrain_svr(X_train_features, y_train_scaled, X_val_features, y_val_scaled)\n\u001b[0;32m     93\u001b[0m model3\u001b[38;5;241m.\u001b[39mpredict_check_mean_square_error(svr_model, X_eval_features)\n",
      "Cell \u001b[1;32mIn[68], line 46\u001b[0m, in \u001b[0;36mModel3.extract_features\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_features\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m# Create feature extraction models\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m     feature_model_1 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m, outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_1\u001b[38;5;241m.\u001b[39mget_layer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_layer_1\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39moutput)\n\u001b[0;32m     47\u001b[0m     feature_model_2 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_2\u001b[38;5;241m.\u001b[39minput, outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_2\u001b[38;5;241m.\u001b[39mget_layer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_layer_2\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39moutput)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# Extract features from the second layers\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\ops\\operation.py:216\u001b[0m, in \u001b[0;36mOperation.input\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minput\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    208\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves the input tensor(s) of a symbolic operation.\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m    Only returns the tensor(s) corresponding to the *first time*\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;124;03m        Input tensor or list of input tensors.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_node_attribute_at_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_tensors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\ops\\operation.py:247\u001b[0m, in \u001b[0;36mOperation._get_node_attribute_at_index\u001b[1;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Private utility to retrieves an attribute (e.g. inputs) from a node.\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \n\u001b[0;32m    233\u001b[0m \u001b[38;5;124;03mThis is used to implement the properties:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03m    The operation's attribute `attr` at the node of index `node_index`.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes:\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    248\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has never been called \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    249\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand thus has no defined \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m     )\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes) \u001b[38;5;241m>\u001b[39m node_index:\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at node \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but the operation has only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m inbound nodes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    256\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The layer sequential_51 has never been called and thus has no defined input."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class Model3:\n",
    "    def __init__(self, X_train, y_train, X_val, y_val, X_eval, y_eval, scalerY):\n",
    "        self.X_train = X_train\n",
    "        self.X_val = X_val\n",
    "        self.X_eval = X_eval\n",
    "        self.y_train = y_train\n",
    "        self.y_val = y_val\n",
    "        self.y_eval = y_eval\n",
    "        self.scalerY = scalerY\n",
    "\n",
    "    def build_model_1(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(Dense(32, activation='sigmoid', kernel_initializer='glorot_uniform'))\n",
    "        model.add(Dense(16, activation='relu', kernel_initializer='he_uniform', name='feature_layer_1'))\n",
    "        model.add(Dense(1, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss='mse', metrics=['mae'])\n",
    "        return model\n",
    "\n",
    "    def build_model_2(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(Dense(32, activation='sigmoid', kernel_initializer='glorot_uniform'))\n",
    "        model.add(Dense(8, activation='sigmoid', kernel_initializer='glorot_normal', name='feature_layer_2'))\n",
    "        model.add(Dense(1, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss='mse', metrics=['mae'])\n",
    "        return model\n",
    "\n",
    "    def train_models(self):\n",
    "        self.model_1 = self.build_model_1()\n",
    "        self.model_2 = self.build_model_2()\n",
    "\n",
    "        # Train Model-1\n",
    "        self.model_1.fit(self.X_train, self.y_train, epochs=20, batch_size=16, validation_data=(self.X_val, self.y_val))\n",
    "\n",
    "        # Train Model-2\n",
    "        self.model_2.fit(self.X_train, self.y_train, epochs=20, batch_size=8, validation_data=(self.X_val, self.y_val))\n",
    "\n",
    "    def extract_features(self):\n",
    "        # Create feature extraction models\n",
    "        feature_model_1 = tf.keras.Model(inputs=self.model_1.input, outputs=self.model_1.get_layer('feature_layer_1').output)\n",
    "        feature_model_2 = tf.keras.Model(inputs=self.model_2.input, outputs=self.model_2.get_layer('feature_layer_2').output)\n",
    "\n",
    "        # Extract features from the second layers\n",
    "        features_1_train = feature_model_1.predict(self.X_train)\n",
    "        features_2_train = feature_model_2.predict(self.X_train)\n",
    "        features_1_val = feature_model_1.predict(self.X_val)\n",
    "        features_2_val = feature_model_2.predict(self.X_val)\n",
    "        features_1_eval = feature_model_1.predict(self.X_eval)\n",
    "        features_2_eval = feature_model_2.predict(self.X_eval)\n",
    "\n",
    "        # Stack the features horizontally\n",
    "        X_train_features = np.hstack([features_1_train, features_2_train])\n",
    "        X_val_features = np.hstack([features_1_val, features_2_val])\n",
    "        X_eval_features = np.hstack([features_1_eval, features_2_eval])\n",
    "\n",
    "        return X_train_features, X_val_features, X_eval_features\n",
    "\n",
    "    def train_svr(self, X_train_features, y_train, X_val_features, y_val):\n",
    "        # Train the Support Vector Regressor\n",
    "        svr = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)\n",
    "        svr.fit(X_train_features, y_train.ravel())\n",
    "\n",
    "        # Predict on validation data\n",
    "        val_predictions = svr.predict(X_val_features)\n",
    "        val_rmse = mean_squared_error(y_val, val_predictions, squared=False)\n",
    "        print(f\"Validation RMSE = {val_rmse}\")\n",
    "\n",
    "        return svr\n",
    "\n",
    "    def predict_check_mean_square_error(self, svr, X_eval_features):\n",
    "        # Make predictions on evaluation data\n",
    "        predictions = svr.predict(X_eval_features)\n",
    "\n",
    "        # Inverse transform the predictions and true values\n",
    "        y_eval_inverse = self.scalerY.inverse_transform(self.y_eval.reshape(-1, 1))\n",
    "        predictions_inverse = self.scalerY.inverse_transform(predictions.reshape(-1, 1))\n",
    "\n",
    "        # Compute RMSE\n",
    "        rmse = mean_squared_error(y_eval_inverse, predictions_inverse, squared=False)\n",
    "        print(f\"Evaluation RMSE = {rmse}\")\n",
    "\n",
    "# Example usage (with correct preprocessing steps for scaling your data):\n",
    "model3 = Model3(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, X_eval_scaled, y_eval_scaled, scalerY)\n",
    "model3.train_models()\n",
    "X_train_features, X_val_features, X_eval_features = model3.extract_features()\n",
    "svr_model = model3.train_svr(X_train_features, y_train_scaled, X_val_features, y_val_scaled)\n",
    "model3.predict_check_mean_square_error(svr_model, X_eval_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bd820c2c-d358-4580-b1d7-133b31445059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rksah\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1547 - mae: 0.3552 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 2/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1550 - mae: 0.3561 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 3/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1552 - mae: 0.3560 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 4/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1569 - mae: 0.3588 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 5/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1572 - mae: 0.3580 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1572 - mae: 0.3576 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 7/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1555 - mae: 0.3564 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 8/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1559 - mae: 0.3570 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 9/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1564 - mae: 0.3577 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 10/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1563 - mae: 0.3569 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 11/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1541 - mae: 0.3540 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 12/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1539 - mae: 0.3544 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 13/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1571 - mae: 0.3585 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 14/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1571 - mae: 0.3586 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 15/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1534 - mae: 0.3531 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 16/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1545 - mae: 0.3549 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 17/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1570 - mae: 0.3582 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 18/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1565 - mae: 0.3585 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 19/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1578 - mae: 0.3591 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 20/20\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1593 - mae: 0.3615 - val_loss: 0.1583 - val_mae: 0.3600\n",
      "Epoch 1/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.1557 - mae: 0.3565 - val_loss: 0.1584 - val_mae: 0.3600\n",
      "Epoch 2/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1565 - mae: 0.3579 - val_loss: 0.1584 - val_mae: 0.3600\n",
      "Epoch 3/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1542 - mae: 0.3555 - val_loss: 0.1584 - val_mae: 0.3600\n",
      "Epoch 4/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1581 - mae: 0.3601 - val_loss: 0.1584 - val_mae: 0.3600\n",
      "Epoch 5/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1573 - mae: 0.3582 - val_loss: 0.1584 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1544 - mae: 0.3540 - val_loss: 0.1584 - val_mae: 0.3600\n",
      "Epoch 7/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1568 - mae: 0.3579 - val_loss: 0.1584 - val_mae: 0.3600\n",
      "Epoch 8/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1567 - mae: 0.3571 - val_loss: 0.1584 - val_mae: 0.3600\n",
      "Epoch 9/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1561 - mae: 0.3573 - val_loss: 0.1584 - val_mae: 0.3600\n",
      "Epoch 10/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1575 - mae: 0.3581 - val_loss: 0.1584 - val_mae: 0.3600\n",
      "Epoch 11/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1560 - mae: 0.3568 - val_loss: 0.1584 - val_mae: 0.3600\n",
      "Epoch 12/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1543 - mae: 0.3552 - val_loss: 0.1584 - val_mae: 0.3600\n",
      "Epoch 13/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1565 - mae: 0.3565 - val_loss: 0.1584 - val_mae: 0.3600\n",
      "Epoch 14/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1556 - mae: 0.3560 - val_loss: 0.1584 - val_mae: 0.3600\n",
      "Epoch 15/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1556 - mae: 0.3565 - val_loss: 0.1584 - val_mae: 0.3600\n",
      "Epoch 16/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1562 - mae: 0.3575 - val_loss: 0.1584 - val_mae: 0.3600\n",
      "Epoch 17/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1527 - mae: 0.3527 - val_loss: 0.1584 - val_mae: 0.3600\n",
      "Epoch 18/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1567 - mae: 0.3574 - val_loss: 0.1584 - val_mae: 0.3600\n",
      "Epoch 19/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1565 - mae: 0.3577 - val_loss: 0.1584 - val_mae: 0.3600\n",
      "Epoch 20/20\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1572 - mae: 0.3581 - val_loss: 0.1584 - val_mae: 0.3600\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The layer sequential_55 has never been called and thus has no defined input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 101\u001b[0m\n\u001b[0;32m     99\u001b[0m model4 \u001b[38;5;241m=\u001b[39m Model4(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, X_eval_scaled, y_eval_scaled, scalerY,X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    100\u001b[0m model4\u001b[38;5;241m.\u001b[39mtrain_models()\n\u001b[1;32m--> 101\u001b[0m X_train_features, X_val_features, X_eval_features \u001b[38;5;241m=\u001b[39m \u001b[43mmodel4\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m X_train_pca, X_val_pca, X_eval_pca \u001b[38;5;241m=\u001b[39m model4\u001b[38;5;241m.\u001b[39mapply_pca(X_train_features, X_val_features, X_eval_features, n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m    103\u001b[0m svr_model \u001b[38;5;241m=\u001b[39m model4\u001b[38;5;241m.\u001b[39mtrain_svr(X_train_pca, y_train_scaled, X_val_pca, y_val_scaled)\n",
      "Cell \u001b[1;32mIn[71], line 47\u001b[0m, in \u001b[0;36mModel4.extract_features\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_features\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m# Create feature extraction models\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m     feature_model_1 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m, outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_1\u001b[38;5;241m.\u001b[39mget_layer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_layer_1\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39moutput)\n\u001b[0;32m     48\u001b[0m     feature_model_2 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_2\u001b[38;5;241m.\u001b[39minput, outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_2\u001b[38;5;241m.\u001b[39mget_layer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_layer_2\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39moutput)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# Extract features from the second layers\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\ops\\operation.py:216\u001b[0m, in \u001b[0;36mOperation.input\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minput\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    208\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves the input tensor(s) of a symbolic operation.\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m    Only returns the tensor(s) corresponding to the *first time*\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;124;03m        Input tensor or list of input tensors.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_node_attribute_at_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_tensors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\ops\\operation.py:247\u001b[0m, in \u001b[0;36mOperation._get_node_attribute_at_index\u001b[1;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Private utility to retrieves an attribute (e.g. inputs) from a node.\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \n\u001b[0;32m    233\u001b[0m \u001b[38;5;124;03mThis is used to implement the properties:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03m    The operation's attribute `attr` at the node of index `node_index`.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes:\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    248\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has never been called \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    249\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand thus has no defined \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m     )\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes) \u001b[38;5;241m>\u001b[39m node_index:\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at node \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but the operation has only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m inbound nodes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    256\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The layer sequential_55 has never been called and thus has no defined input."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class Model4:\n",
    "    def __init__(self, X_train, y_train, X_val, y_val, X_eval, y_eval, scalerY, input_dim):\n",
    "        self.X_train = X_train\n",
    "        self.X_val = X_val\n",
    "        self.X_eval = X_eval\n",
    "        self.y_train = y_train\n",
    "        self.y_val = y_val\n",
    "        self.y_eval = y_eval\n",
    "        self.scalerY = scalerY\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def build_model_1(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(Dense(32, activation='sigmoid', kernel_initializer='glorot_uniform', input_shape=(self.input_dim,)))\n",
    "        model.add(Dense(16, activation='relu', kernel_initializer='he_uniform', name='feature_layer_1'))\n",
    "        model.add(Dense(1, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss='mse', metrics=['mae'])\n",
    "        return model\n",
    "\n",
    "    def build_model_2(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(Dense(32, activation='sigmoid', kernel_initializer='glorot_uniform', input_shape=(self.input_dim,)))\n",
    "        model.add(Dense(8, activation='sigmoid', kernel_initializer='glorot_normal', name='feature_layer_2'))\n",
    "        model.add(Dense(1, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss='mse', metrics=['mae'])\n",
    "        return model\n",
    "\n",
    "    def train_models(self):\n",
    "        self.model_1 = self.build_model_1()\n",
    "        self.model_2 = self.build_model_2()\n",
    "\n",
    "        # Train Model-1\n",
    "        self.model_1.fit(self.X_train, self.y_train, epochs=20, batch_size=16, validation_data=(self.X_val, self.y_val))\n",
    "\n",
    "        # Train Model-2\n",
    "        self.model_2.fit(self.X_train, self.y_train, epochs=20, batch_size=8, validation_data=(self.X_val, self.y_val))\n",
    "\n",
    "    def extract_features(self):\n",
    "        # Create feature extraction models\n",
    "        feature_model_1 = tf.keras.Model(inputs=self.model_1.input, outputs=self.model_1.get_layer('feature_layer_1').output)\n",
    "        feature_model_2 = tf.keras.Model(inputs=self.model_2.input, outputs=self.model_2.get_layer('feature_layer_2').output)\n",
    "\n",
    "        # Extract features from the second layers\n",
    "        features_1_train = feature_model_1.predict(self.X_train)\n",
    "        features_2_train = feature_model_2.predict(self.X_train)\n",
    "        features_1_val = feature_model_1.predict(self.X_val)\n",
    "        features_2_val = feature_model_2.predict(self.X_val)\n",
    "        features_1_eval = feature_model_1.predict(self.X_eval)\n",
    "        features_2_eval = feature_model_2.predict(self.X_eval)\n",
    "\n",
    "        # Stack the features horizontally\n",
    "        X_train_features = np.hstack([features_1_train, features_2_train])\n",
    "        X_val_features = np.hstack([features_1_val, features_2_val])\n",
    "        X_eval_features = np.hstack([features_1_eval, features_2_eval])\n",
    "\n",
    "        return X_train_features, X_val_features, X_eval_features\n",
    "\n",
    "    def apply_pca(self, X_train_features, X_val_features, X_eval_features, n_components=10):\n",
    "        # Apply PCA to reduce the dimensionality\n",
    "        from sklearn.decomposition import PCA\n",
    "        pca = PCA(n_components=n_components)\n",
    "        X_train_pca = pca.fit_transform(X_train_features)\n",
    "        X_val_pca = pca.transform(X_val_features)\n",
    "        X_eval_pca = pca.transform(X_eval_features)\n",
    "\n",
    "        return X_train_pca, X_val_pca, X_eval_pca\n",
    "\n",
    "    def train_svr(self, X_train_pca, y_train, X_val_pca, y_val):\n",
    "        # Train the Support Vector Regressor\n",
    "        svr = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)\n",
    "        svr.fit(X_train_pca, y_train.ravel())\n",
    "\n",
    "        # Predict on validation data\n",
    "        val_predictions = svr.predict(X_val_pca)\n",
    "        val_rmse = mean_squared_error(y_val, val_predictions, squared=False)\n",
    "        print(f\"Validation RMSE = {val_rmse}\")\n",
    "\n",
    "        return svr\n",
    "\n",
    "    def predict_check_mean_square_error(self, svr, X_eval_pca):\n",
    "        # Make predictions on evaluation data\n",
    "        predictions = svr.predict(X_eval_pca)\n",
    "\n",
    "        # Inverse transform the predictions and true values\n",
    "        y_eval_inverse = self.scalerY.inverse_transform(self.y_eval.reshape(-1, 1))\n",
    "        predictions_inverse = self.scalerY.inverse_transform(predictions.reshape(-1, 1))\n",
    "\n",
    "        # Compute RMSE\n",
    "        rmse = mean_squared_error(y_eval_inverse, predictions_inverse, squared=False)\n",
    "        print(f\"Evaluation RMSE = {rmse}\")\n",
    "\n",
    "model4 = Model4(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled, X_eval_scaled, y_eval_scaled, scalerY,X_train.shape[1])\n",
    "model4.train_models()\n",
    "X_train_features, X_val_features, X_eval_features = model4.extract_features()\n",
    "X_train_pca, X_val_pca, X_eval_pca = model4.apply_pca(X_train_features, X_val_features, X_eval_features, n_components=10)\n",
    "svr_model = model4.train_svr(X_train_pca, y_train_scaled, X_val_pca, y_val_scaled)\n",
    "model4.predict_check_mean_square_error(svr_model, X_eval_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34459d32-6fc5-477d-9041-01c06e1de22e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
